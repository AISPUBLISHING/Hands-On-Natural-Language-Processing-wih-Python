{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Bag of Words Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he': 4, 'likes': 6, 'to': 8, 'watch': 9, 'movies': 7, 'french': 2, 'are': 0, 'good': 3, 'do': 1, 'you': 10, 'like': 5}\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"He likes to watch movies\",\n",
    "          \"French movies are good to watch movies\",\n",
    "          \"Do you like French movies?\"]\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bog_vectorizer = CountVectorizer()\n",
    "\n",
    "bog_vectorizer.fit(corpus)\n",
    "print(bog_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He likes to watch movies --> [[0 0 0 0 1 0 1 1 1 1 0]]\n",
      "French movies are good to watch movies --> [[1 0 1 1 0 0 0 2 1 1 0]]\n",
      "Do you like French movies? --> [[0 1 1 0 0 1 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "bog_vectors =  bog_vectorizer.transform(corpus)\n",
    "for i in range(len(corpus)):\n",
    "    print(corpus[i],\"-->\",bog_vectors[i].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'likes': 3, 'watch': 5, 'movies': 4, 'french': 0, 'good': 1, 'like': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bog_vectorizer = CountVectorizer(stop_words=[\"to\", \"you\", \"are\", \"he\", \"do\"])\n",
    "\n",
    "bog_vectorizer.fit(corpus)\n",
    "print(bog_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He likes to watch movies --> [[0 0 0 1 1 1]]\n",
      "French movies are good to watch movies --> [[1 1 0 0 2 1]]\n",
      "Do you like French movies? --> [[1 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "bog_vectors =  bog_vectorizer.transform(corpus)\n",
    "for i in range(len(corpus)):\n",
    "    print(corpus[i],\"-->\",bog_vectors[i].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. N-Grams Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he likes': 4, 'likes to': 6, 'to watch': 8, 'watch movies': 9, 'french movies': 2, 'movies are': 7, 'are good': 0, 'good to': 3, 'do you': 1, 'you like': 10, 'like french': 5}\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"He likes to watch movies\",\n",
    "          \"French movies are good to watch movies\",\n",
    "          \"Do you like French movies?\"]\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "ng_vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "ng_vectorizer.fit(corpus)\n",
    "print(ng_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He likes to watch movies --> [[0 0 0 1 1 1]]\n",
      "French movies are good to watch movies --> [[1 1 0 0 2 1]]\n",
      "Do you like French movies? --> [[1 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "ng_vectors =  ng_vectorizer.transform(corpus)\n",
    "for i in range(len(corpus)):\n",
    "    print(corpus[i],\"-->\",ng_vectors[i].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. TF-IDF Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'likes': 3, 'watch': 5, 'movies': 4, 'french': 0, 'good': 1, 'like': 2}\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"He likes to watch movies\",\n",
    "          \"French movies are good to watch movies\",\n",
    "          \"Do you like French movies?\"]\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He likes to watch movies --> [[0.         0.         0.         0.72033345 0.42544054 0.54783215]]\n",
      "French movies are good to watch movies --> [[0.40352536 0.53058735 0.         0.         0.62674687 0.40352536]]\n",
      "Do you like French movies? --> [[0.54783215 0.         0.72033345 0.         0.42544054 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectors =  tfidf_vectorizer.transform(corpus)\n",
    "for i in range(len(corpus)):\n",
    "    print(corpus[i],\"-->\",tfidf_vectors[i].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['french', 'good', 'like', 'likes', 'movies', 'watch']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>french</td>\n",
       "      <td>1.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>good</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>like</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>likes</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>movies</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>watch</td>\n",
       "      <td>1.287682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             idf\n",
       "french  1.287682\n",
       "good    1.693147\n",
       "like    1.693147\n",
       "likes   1.693147\n",
       "movies  1.000000\n",
       "watch   1.287682"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(tfidf_vectorizer.idf_,index=['french', 'good', 'like', 'likes', 'movies', 'watch'],columns=['idf'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>french</td>\n",
       "      <td>1.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>good</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>like</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>likes</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>movies</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>watch</td>\n",
       "      <td>1.287682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tf\n",
       "french  1.287682\n",
       "good    1.693147\n",
       "like    1.693147\n",
       "likes   1.693147\n",
       "movies  1.000000\n",
       "watch   1.287682"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(tfidf_vectorizer.idf_,index=['french', 'good', 'like', 'likes', 'movies', 'watch'],columns=['tf'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>good</th>\n",
       "      <th>like</th>\n",
       "      <th>likes</th>\n",
       "      <th>movies</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.403525</td>\n",
       "      <td>0.530587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626747</td>\n",
       "      <td>0.403525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     french      good      like     likes    movies     watch\n",
       "0  0.000000  0.000000  0.000000  0.720333  0.425441  0.547832\n",
       "1  0.403525  0.530587  0.000000  0.000000  0.626747  0.403525\n",
       "2  0.547832  0.000000  0.720333  0.000000  0.425441  0.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(tfidf_vectors.todense(),columns=['french', 'good', 'like', 'likes', 'movies', 'watch'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file: file\n",
    "file = open(\"E:\\Datasets\\simple_textfile.txt\",mode='r')\n",
    " \n",
    "\n",
    "corpus = file.read()\n",
    " \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "processed_corpus = corpus.lower()\n",
    "processed_corpus = re.sub('[^a-zA-Z]', ' ', processed_corpus)\n",
    "processed_corpus = re.sub(r'\\s+', ' ', processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "all_sentences = nltk.sent_tokenize(processed_corpus)\n",
    "\n",
    "all_tokens = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "\n",
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_tokens)):\n",
    "    all_tokens[i] = [w for w in all_tokens[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "custom_embeddings = Word2Vec(all_tokens, size = 50, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00426598  0.0066667  -0.00994872 -0.0018594  -0.00368378 -0.00152758\n",
      " -0.00074282  0.00785413 -0.00063565  0.00349408  0.00979154 -0.00473177\n",
      "  0.00720627 -0.00183818 -0.00537117  0.00785426  0.00251265  0.00769123\n",
      " -0.00811501 -0.00216821 -0.00799533  0.00863134 -0.00185704  0.00969618\n",
      "  0.0028168  -0.00972727  0.00881161  0.00715959  0.00634548  0.00720468\n",
      "  0.00580982  0.00541707  0.00326962  0.00124786 -0.00173341 -0.00210726\n",
      "  0.00082567  0.00168776  0.00956614  0.007015   -0.00264531 -0.00101851\n",
      " -0.00378467 -0.0045118   0.00485406  0.00942281 -0.00058634  0.00399187\n",
      " -0.00708318 -0.00132198]\n"
     ]
    }
   ],
   "source": [
    "embedding = custom_embeddings.wv['language']\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('research', 0.23508717119693756), ('words', 0.20266640186309814), ('g', 0.2025955319404602), ('soft', 0.17397646605968475), ('accurate', 0.15688738226890564), ('simply', 0.1476944088935852), ('large', 0.13822558522224426), ('made', 0.1043497771024704), ('data', 0.08629055321216583), ('systems', 0.08272531628608704)]\n"
     ]
    }
   ],
   "source": [
    "embedding = custom_embeddings.wv.most_similar(\"processing\")\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_embeddings.save(\"E:\\Datasets\\custom_embeddings.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00426598  0.0066667  -0.00994872 -0.0018594  -0.00368378 -0.00152758\n",
      " -0.00074282  0.00785413 -0.00063565  0.00349408  0.00979154 -0.00473177\n",
      "  0.00720627 -0.00183818 -0.00537117  0.00785426  0.00251265  0.00769123\n",
      " -0.00811501 -0.00216821 -0.00799533  0.00863134 -0.00185704  0.00969618\n",
      "  0.0028168  -0.00972727  0.00881161  0.00715959  0.00634548  0.00720468\n",
      "  0.00580982  0.00541707  0.00326962  0.00124786 -0.00173341 -0.00210726\n",
      "  0.00082567  0.00168776  0.00956614  0.007015   -0.00264531 -0.00101851\n",
      " -0.00378467 -0.0045118   0.00485406  0.00942281 -0.00058634  0.00399187\n",
      " -0.00708318 -0.00132198]\n"
     ]
    }
   ],
   "source": [
    "custom_embeddings_loaded = Word2Vec.load(\"E:\\Datasets\\custom_embeddings.model\")\n",
    "embedding_loaded = custom_embeddings_loaded.wv['language']\n",
    "print(embedding_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Using Pretrained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove2word2vec(glove_input_file=\"E:\\Datasets\\glove.6B.100d.txt\", word2vec_output_file=\"E:\\Datasets\\gensim_glove_vectors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"E:\\Datasets\\gensim_glove_vectors.txt\", binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18519 ,  0.34111 ,  0.36097 ,  0.27093 , -0.031335,  0.83923 ,\n",
       "       -0.50534 , -0.80062 ,  0.40695 ,  0.82488 , -0.98239 , -0.6354  ,\n",
       "       -0.21382 ,  0.079889, -0.29557 ,  0.17075 ,  0.17479 , -0.74214 ,\n",
       "       -0.2677  ,  0.21074 , -0.41795 ,  0.027713,  0.71123 ,  0.2063  ,\n",
       "       -0.12266 , -0.80088 ,  0.22942 ,  0.041037, -0.56901 ,  0.097472,\n",
       "       -0.59139 ,  1.0524  , -0.66803 , -0.70471 ,  0.69757 , -0.11137 ,\n",
       "       -0.27816 ,  0.047361,  0.020305, -0.184   , -1.0254  ,  0.11297 ,\n",
       "       -0.79547 ,  0.41642 , -0.2508  , -0.3188  ,  0.37044 , -0.26873 ,\n",
       "       -0.36185 , -0.096621, -0.029956,  0.67308 ,  0.53102 ,  0.62816 ,\n",
       "       -0.11507 , -1.5524  , -0.30628 , -0.4253  ,  1.8887  ,  0.3247  ,\n",
       "        0.60202 ,  0.81163 , -0.46029 , -1.4061  ,  0.80229 ,  0.2019  ,\n",
       "        0.60938 ,  0.063545,  0.21925 , -0.043372, -0.36648 ,  0.61308 ,\n",
       "        1.0207  , -0.39014 ,  0.1717  ,  0.61272 , -0.80342 ,  0.71295 ,\n",
       "       -1.0938  , -0.50546 , -0.99668 , -1.6701  , -0.31804 , -0.62934 ,\n",
       "       -2.0226  ,  0.79405 , -0.16994 , -0.37627 ,  0.57998 ,  0.16643 ,\n",
       "        0.1356  ,  0.0943  , -0.24154 ,  0.7123  , -0.4201  ,  0.24735 ,\n",
       "       -0.94449 , -1.0794  ,  0.3413  ,  0.34704 ], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cia', 0.742180585861206),\n",
       " ('information', 0.7210196256637573),\n",
       " ('security', 0.6963101625442505),\n",
       " ('fbi', 0.6962289810180664),\n",
       " ('military', 0.6934822201728821),\n",
       " ('secret', 0.6893364191055298),\n",
       " ('counterterrorism', 0.6762625575065613),\n",
       " ('pentagon', 0.6651185154914856),\n",
       " ('defense', 0.6564568281173706),\n",
       " ('agents', 0.6406551599502563)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar('intelligence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1\n",
    "\n",
    "**Question 1:** Which of the following is not a disadvantage of Bag of Words and NGrams Approach\n",
    "\n",
    "A. Results in a huge sparse matrix\n",
    "\n",
    "B. Context information is not retained\n",
    "\n",
    "C. Requires huge amount of data to train\n",
    "\n",
    "D. None of the above\n",
    "\n",
    "**Answer:** C\n",
    "\n",
    "\n",
    "**Question 2:** Which attribute is used to specify range of N-Grams via Sklearn's CountVectorizer\n",
    "\n",
    "A. ngrams\n",
    "\n",
    "B. ng_rage\n",
    "\n",
    "C. ngrams_range\n",
    "\n",
    "D. ngram_range\n",
    "\n",
    "**Answer:** D\n",
    "\n",
    "\n",
    "\n",
    "**Question 2:** Suppose you develop a custom word2vec model \"GensimModel\" with Gensim. How will you display words similar to \"Machine\"?\n",
    "\n",
    "A. GensimModel.wv.most_similar(\"Machine\")\n",
    "\n",
    "B. GensimModel.most_similar(\"Machine\")\n",
    "\n",
    "C. GensimModel.wv.similar(\"Machine\")\n",
    "\n",
    "D. GensimModel.similar(\"Machine\")\n",
    "\n",
    "**Answer:** A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.2\n",
    "\n",
    "Using the following corpus, create bag of words and TFIDF models without stopwords. Display the original words and the bag of words and TFIDF vectors:\n",
    "\n",
    "dataset = [\n",
    "\n",
    "    'This movie is excellent',\n",
    "    'I loved the movie, it was fantastic',\n",
    "    'The film is brilliant, you should watch',\n",
    "    'Wonderful movie',\n",
    "    'one of the best films ever',\n",
    "    'fantastic film to watch',\n",
    "    'great movie',\n",
    "    'Acting and direction is brilliant'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is excellent --> [[0 0 0 0 1 0 0 0 0 0 1 0 0]]\n",
      "I loved the movie, it was fantastic --> [[0 0 0 0 0 1 0 0 0 1 1 0 0]]\n",
      "The film is brilliant, you should watch --> [[0 0 1 0 0 0 1 0 0 0 0 1 0]]\n",
      "Wonderful movie --> [[0 0 0 0 0 0 0 0 0 0 1 0 1]]\n",
      "one of the best films ever --> [[0 1 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "fantastic film to watch --> [[0 0 0 0 0 1 1 0 0 0 0 1 0]]\n",
      "great movie --> [[0 0 0 0 0 0 0 0 1 0 1 0 0]]\n",
      "Acting and direction is brilliant --> [[1 0 1 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "dataset = [\n",
    "\n",
    "    'This movie is excellent',\n",
    "    'I loved the movie, it was fantastic',\n",
    "    'The film is brilliant, you should watch',\n",
    "    'Wonderful movie',\n",
    "    'one of the best films ever',\n",
    "    'fantastic film to watch',\n",
    "    'great movie',\n",
    "    'Acting and direction is brilliant'\n",
    "]\n",
    "\n",
    "\n",
    "## Bag of Words Approach\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bog_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "bog_vectorizer.fit(dataset)\n",
    "\n",
    "bog_vectors =  bog_vectorizer.transform(dataset)\n",
    "for i in range(len(dataset)):\n",
    "    print(dataset[i],\"-->\",bog_vectors[i].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is excellent --> [[0.         0.         0.         0.         0.84453372 0.\n",
      "  0.         0.         0.         0.         0.53550237 0.\n",
      "  0.        ]]\n",
      "I loved the movie, it was fantastic --> [[0.         0.         0.         0.         0.         0.57771936\n",
      "  0.         0.         0.         0.68933838 0.43709603 0.\n",
      "  0.        ]]\n",
      "The film is brilliant, you should watch --> [[0.         0.         0.57735027 0.         0.         0.\n",
      "  0.57735027 0.         0.         0.         0.         0.57735027\n",
      "  0.        ]]\n",
      "Wonderful movie --> [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.53550237 0.\n",
      "  0.84453372]]\n",
      "one of the best films ever --> [[0.         0.70710678 0.         0.         0.         0.\n",
      "  0.         0.70710678 0.         0.         0.         0.\n",
      "  0.        ]]\n",
      "fantastic film to watch --> [[0.         0.         0.         0.         0.         0.57735027\n",
      "  0.57735027 0.         0.         0.         0.         0.57735027\n",
      "  0.        ]]\n",
      "great movie --> [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.84453372 0.         0.53550237 0.\n",
      "  0.        ]]\n",
      "Acting and direction is brilliant --> [[0.60831315 0.         0.5098139  0.60831315 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "## TFIDF Approach\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf_vectorizer.fit(dataset)\n",
    "\n",
    "tfidf_vectors =  tfidf_vectorizer.transform(dataset)\n",
    "for i in range(len(dataset)):\n",
    "    print(dataset[i],\"-->\",tfidf_vectors[i].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
