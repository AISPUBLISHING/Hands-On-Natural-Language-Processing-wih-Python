{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Text Summarization with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ pip install beautifulsoup4\n",
    "# $ pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.1. Scrapping Wikipedia Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "raw_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "document = raw_data.read()\n",
    "\n",
    "parsed_document = bs.BeautifulSoup(document,'lxml')\n",
    "\n",
    "article_paras = parsed_document.find_all('p')\n",
    "\n",
    "scrapped_data = \"\"\n",
    "\n",
    "for para in article_paras:\n",
    "    scrapped_data += para.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
      "Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\n",
      "The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods.\n",
      "In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence[clarification needed].\n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved p\n"
     ]
    }
   ],
   "source": [
    "print(scrapped_data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2. Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapped_data = re.sub(r'\\[[0-9]*\\]', ' ',  scrapped_data)\n",
    "scrapped_data = re.sub(r'\\s+', ' ',  scrapped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_text = re.sub('[^a-zA-Z]', ' ', scrapped_data)\n",
    "formatted_text = re.sub(r'\\s+', ' ', formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.3. Finding Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "all_sentences = nltk.sent_tokenize(scrapped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "word_freq = {}\n",
    "for word in nltk.word_tokenize(formatted_text):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_freq = max(word_freq.values())\n",
    "\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word] = (word_freq[word]/max_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.4. Finding Sentence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sentence in all_sentences:\n",
    "    for token in nltk.word_tokenize(sentence.lower()):\n",
    "        if token in word_freq.keys():\n",
    "            if len(sentence.split(' ')) <25:\n",
    "                if sentence not in sentence_scores.keys():\n",
    "                    sentence_scores[sentence] = word_freq[token]\n",
    "                else:\n",
    "                    sentence_scores[sentence] += word_freq[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.5. Printing Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. Since the so-called \"statistical revolution\" in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning. Little further research in machine translation was conducted until the late 1980s when the first statistical machine translation systems were developed. Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "selected_sentences= heapq.nlargest(5, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "text_summary = ' '.join(selected_sentences)\n",
    "print(text_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
